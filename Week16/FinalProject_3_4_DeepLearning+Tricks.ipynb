{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    },
    "colab": {
      "name": "FinalProject - 3 DeepLearning.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7AUYl1TAd-UG"
      },
      "source": [
        "# 三+四、模型调优-神经网络的实现及训练过程的优化"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qTAEooe-d-UL",
        "outputId": "8549c064-e9ed-4523-dc94-1520eb4df510"
      },
      "source": [
        "!pip install pytorch-tabnet"
      ],
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: pytorch-tabnet in /usr/local/lib/python3.7/dist-packages (3.1.1)\n",
            "Requirement already satisfied: numpy<2.0,>=1.17 in /usr/local/lib/python3.7/dist-packages (from pytorch-tabnet) (1.19.5)\n",
            "Requirement already satisfied: torch<2.0,>=1.2 in /usr/local/lib/python3.7/dist-packages (from pytorch-tabnet) (1.8.1+cu101)\n",
            "Requirement already satisfied: scipy>1.4 in /usr/local/lib/python3.7/dist-packages (from pytorch-tabnet) (1.4.1)\n",
            "Requirement already satisfied: scikit_learn>0.21 in /usr/local/lib/python3.7/dist-packages (from pytorch-tabnet) (0.22.2.post1)\n",
            "Requirement already satisfied: tqdm<5.0,>=4.36 in /usr/local/lib/python3.7/dist-packages (from pytorch-tabnet) (4.41.1)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch<2.0,>=1.2->pytorch-tabnet) (3.7.4.3)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit_learn>0.21->pytorch-tabnet) (1.0.1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2939-3Whd-UM"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from pytorch_tabnet.tab_model import TabNetClassifier, TabNetRegressor"
      ],
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2d0inbscd-UM"
      },
      "source": [
        "def reduce_mem_usage(df):\n",
        "    '''\n",
        "    遍历DataFrame的所有列并修改它们的数据类型以减少内存使用\n",
        "    :param df: 需要处理的数据集\n",
        "    :return:\n",
        "    '''\n",
        "    start_mem = df.memory_usage().sum() / 1024 ** 2  # 记录原数据的内存大小\n",
        "    print('Memory usage of dataframe is {:.2f} MB'.format(start_mem))\n",
        "    for col in df.columns:\n",
        "        col_type = df[col].dtypes\n",
        "        if col_type != object:  # 这里只过滤了object格式，如果代码中还包含其他类型，要一并过滤\n",
        "            c_min = df[col].min()\n",
        "            c_max = df[col].max()\n",
        "            if str(col_type)[:3] == 'int':  # 如果是int类型的话,不管是int64还是int32,都加入判断\n",
        "                # 依次尝试转化成in8,in16,in32,in64类型,如果数据大小没溢出,那么转化\n",
        "                if c_min > np.iinfo(np.int8).min and c_max < np.iinfo(np.int8).max:\n",
        "                    df[col] = df[col].astype(np.int8)\n",
        "                elif c_min > np.iinfo(np.int16).min and c_max < np.iinfo(np.int16).max:\n",
        "                    df[col] = df[col].astype(np.int16)\n",
        "                elif c_min > np.iinfo(np.int32).min and c_max < np.iinfo(np.int32).max:\n",
        "                    df[col] = df[col].astype(np.int32)\n",
        "                elif c_min > np.iinfo(np.int64).min and c_max < np.iinfo(np.int64).max:\n",
        "                    df[col] = df[col].astype(np.int64)\n",
        "            else:  # 不是整形的话,那就是浮点型\n",
        "                if c_min > np.finfo(np.float16).min and c_max < np.finfo(np.float16).max:\n",
        "                    df[col] = df[col].astype(np.float16)\n",
        "                elif c_min > np.finfo(np.float32).min and c_max < np.finfo(np.float32).max:\n",
        "                    df[col] = df[col].astype(np.float32)\n",
        "                else:\n",
        "                    df[col] = df[col].astype(np.float64)\n",
        "        else:  # 如果不是数值型的话,转化成category类型\n",
        "            df[col] = df[col].astype('category')\n",
        "\n",
        "    end_mem = df.memory_usage().sum() / 1024 ** 2    # 看一下转化后的数据的内存大小\n",
        "    print('Memory usage after optimization is {:.2f} MB'.format(end_mem))\n",
        "    print('Decreased by {:.1f}%'.format(100 * (start_mem - end_mem) / start_mem))  # 看一下压缩比例\n",
        "    return df"
      ],
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dcyUraWWd-UN",
        "outputId": "060e3f9b-8562-4e13-f26d-f27a5356cab5"
      },
      "source": [
        "train_data = reduce_mem_usage(pd.read_csv('/content/drive/My Drive/final-ml/train_final.csv'))\n",
        "test_data = reduce_mem_usage(pd.read_csv('/content/drive/My Drive/final-ml/test_final.csv'))"
      ],
      "execution_count": 96,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Memory usage of dataframe is 55.69 MB\n",
            "Memory usage after optimization is 8.11 MB\n",
            "Decreased by 85.4%\n",
            "Memory usage of dataframe is 55.69 MB\n",
            "Memory usage after optimization is 8.11 MB\n",
            "Decreased by 85.4%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ldMjcz6Qe_d2",
        "outputId": "7e0d797c-8071-4b38-acfc-2337efbb6b4b"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tKz3RoMhd-UN"
      },
      "source": [
        "train_data.fillna(0, inplace=True)\n",
        "test_data.fillna(0, inplace=True)"
      ],
      "execution_count": 97,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XbLcYiiPd-UN"
      },
      "source": [
        "## a）TabNet的实现"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IysDgYZod-UN"
      },
      "source": [
        "# 准备数据\n",
        "DL_train, DL_test = train_data.copy(), test_data.copy()\n",
        "X_train, Y_train = DL_train.drop(columns='loan_status').values, DL_train['loan_status'].values.astype(int)\n",
        "X_test, Y_test = DL_test.drop(columns='loan_status').values, DL_test['loan_status'].values.astype(int)"
      ],
      "execution_count": 98,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "ynSXRvBGd-UO"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_eval, Y_train, Y_eval = train_test_split(X_train, Y_train, test_size=0.3, random_state=4)"
      ],
      "execution_count": 71,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "pG14-SoBd-UO",
        "outputId": "2bf6fbfa-654f-41db-8aa7-58a6f282ed2e"
      },
      "source": [
        "# 构建模型\n",
        "tn = TabNetClassifier()\n",
        "tn.fit(X_train, Y_train, \n",
        "       eval_set=[(X_eval, Y_eval)], \n",
        "      eval_metric = ['logloss'])\n",
        "preds = tn.predict(X_test)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Device used : cpu\n",
            "epoch 0  | loss: 0.43578 | val_0_logloss: 2.71898 |  0:00:02s\n",
            "epoch 1  | loss: 0.24606 | val_0_logloss: 1.04697 |  0:00:04s\n",
            "epoch 2  | loss: 0.23373 | val_0_logloss: 1.33253 |  0:00:06s\n",
            "epoch 3  | loss: 0.22719 | val_0_logloss: 0.93691 |  0:00:08s\n",
            "epoch 4  | loss: 0.22218 | val_0_logloss: 0.60842 |  0:00:11s\n",
            "epoch 5  | loss: 0.21623 | val_0_logloss: 0.40839 |  0:00:13s\n",
            "epoch 6  | loss: 0.21465 | val_0_logloss: 0.30493 |  0:00:15s\n",
            "epoch 7  | loss: 0.21237 | val_0_logloss: 0.24692 |  0:00:17s\n",
            "epoch 8  | loss: 0.21144 | val_0_logloss: 0.23349 |  0:00:20s\n",
            "epoch 9  | loss: 0.20993 | val_0_logloss: 0.21921 |  0:00:22s\n",
            "epoch 10 | loss: 0.20732 | val_0_logloss: 0.21032 |  0:00:24s\n",
            "epoch 11 | loss: 0.20827 | val_0_logloss: 0.21315 |  0:00:26s\n",
            "epoch 12 | loss: 0.20504 | val_0_logloss: 0.21277 |  0:00:28s\n",
            "epoch 13 | loss: 0.20515 | val_0_logloss: 0.21061 |  0:00:30s\n",
            "epoch 14 | loss: 0.20577 | val_0_logloss: 0.21539 |  0:00:33s\n",
            "epoch 15 | loss: 0.20461 | val_0_logloss: 0.20968 |  0:00:35s\n",
            "epoch 16 | loss: 0.20401 | val_0_logloss: 0.21353 |  0:00:37s\n",
            "epoch 17 | loss: 0.20368 | val_0_logloss: 0.20962 |  0:00:39s\n",
            "epoch 18 | loss: 0.20294 | val_0_logloss: 0.2103  |  0:00:41s\n",
            "epoch 19 | loss: 0.20271 | val_0_logloss: 0.21049 |  0:00:44s\n",
            "epoch 20 | loss: 0.20228 | val_0_logloss: 0.21148 |  0:00:46s\n",
            "epoch 21 | loss: 0.20113 | val_0_logloss: 0.21163 |  0:00:48s\n",
            "epoch 22 | loss: 0.19995 | val_0_logloss: 0.21268 |  0:00:50s\n",
            "epoch 23 | loss: 0.19929 | val_0_logloss: 0.21191 |  0:00:53s\n",
            "epoch 24 | loss: 0.19919 | val_0_logloss: 0.20906 |  0:00:55s\n",
            "epoch 25 | loss: 0.19849 | val_0_logloss: 0.21048 |  0:00:58s\n",
            "epoch 26 | loss: 0.19761 | val_0_logloss: 0.20815 |  0:01:00s\n",
            "epoch 27 | loss: 0.19731 | val_0_logloss: 0.20829 |  0:01:02s\n",
            "epoch 28 | loss: 0.19691 | val_0_logloss: 0.20797 |  0:01:04s\n",
            "epoch 29 | loss: 0.19581 | val_0_logloss: 0.20857 |  0:01:07s\n",
            "epoch 30 | loss: 0.19626 | val_0_logloss: 0.21057 |  0:01:09s\n",
            "epoch 31 | loss: 0.19604 | val_0_logloss: 0.21017 |  0:01:11s\n",
            "epoch 32 | loss: 0.19454 | val_0_logloss: 0.20775 |  0:01:13s\n",
            "epoch 33 | loss: 0.19343 | val_0_logloss: 0.20979 |  0:01:15s\n",
            "epoch 34 | loss: 0.19383 | val_0_logloss: 0.20778 |  0:01:18s\n",
            "epoch 35 | loss: 0.19247 | val_0_logloss: 0.20722 |  0:01:20s\n",
            "epoch 36 | loss: 0.19298 | val_0_logloss: 0.20829 |  0:01:22s\n",
            "epoch 37 | loss: 0.19107 | val_0_logloss: 0.20794 |  0:01:24s\n",
            "epoch 38 | loss: 0.19191 | val_0_logloss: 0.20772 |  0:01:26s\n",
            "epoch 39 | loss: 0.19091 | val_0_logloss: 0.20839 |  0:01:29s\n",
            "epoch 40 | loss: 0.18909 | val_0_logloss: 0.21485 |  0:01:31s\n",
            "epoch 41 | loss: 0.18834 | val_0_logloss: 0.21155 |  0:01:33s\n",
            "epoch 42 | loss: 0.1871  | val_0_logloss: 0.21156 |  0:01:35s\n",
            "epoch 43 | loss: 0.18827 | val_0_logloss: 0.21    |  0:01:38s\n",
            "epoch 44 | loss: 0.18633 | val_0_logloss: 0.20962 |  0:01:40s\n",
            "epoch 45 | loss: 0.19538 | val_0_logloss: 0.20996 |  0:01:42s\n",
            "\n",
            "Early stopping occurred at epoch 45 with best_epoch = 35 and best_val_0_logloss = 0.20722\n",
            "Best weights from best epoch are automatically used!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6vrA4nDxd-UO",
        "outputId": "bfef62d0-b671-4c39-d56b-234adfcebdc3"
      },
      "source": [
        "from sklearn.metrics import accuracy_score\n",
        "accuracy_score(Y_test, preds)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.91602"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 75
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3lqjLYu-d-UO"
      },
      "source": [
        "### TabNet + tricks"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CVe-rO7Pd-UO"
      },
      "source": [
        "#### 半监督预训练"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "paU8b81bd-UP"
      },
      "source": [
        "import torch\n",
        "from pytorch_tabnet.pretraining import TabNetPretrainer\n",
        "\n",
        "tn_pre = TabNetPretrainer(\n",
        "        optimizer_fn = torch.optim.Adam,\n",
        "        optimizer_params = dict(lr=2e-2),\n",
        "        mask_type='entmax'\n",
        ")\n",
        "\n",
        "tn_pre.fit(\n",
        "    X_train = X_train,\n",
        "    eval_set = [X_eval],\n",
        "    pretraining_ratio=0.8\n",
        ")\n",
        "\n",
        "tn1 = TabNetClassifier(\n",
        "        optimizer_fn=torch.optim.Adadelta,\n",
        "        optimizer_params=dict(lr=2e-2),\n",
        "        scheduler_params={'step_size':10, 'gamma': 0.9},\n",
        "        scheduler_fn=torch.optim.lr_scheduler.StepLR,\n",
        "        mask_type='sparsemax'\n",
        ")\n",
        "\n",
        "tn1.fit(\n",
        "    X_train=X_train, y_train=Y_train,\n",
        "    eval_set=[(X_eval, Y_eval)],\n",
        "    eval_metric=['logloss'],\n",
        "    from_unsupervised=tn_pre,\n",
        "    max_epochs=200\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ow_EU5xEd-UP",
        "outputId": "37aada44-2dfb-45de-af5f-ded51284fc34"
      },
      "source": [
        "from sklearn.metrics import accuracy_score\n",
        "preds = tn1.predict(X_test)\n",
        "accuracy_score(Y_test, preds)"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.80452"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SSa9RgqgjNBw"
      },
      "source": [
        "##### fine-tune阶段选择不同的优化器，max_epochs=100， init_lr=2e-2 情形下，分别的准确率\n",
        "- Adam：0.91512\n",
        "- SGD：0.80452\n",
        "- Adadelta：0.80452\n",
        "- 初步结论：Adam能够保证适当速度收敛，而SGD和Adadelta实在太慢。但当使用Adam得到最佳准确率时，并pretrain和finetune均未训练满100个epoch就停下了，所以再增加epochs也无法进一步提升准确率。故考虑改变预训练比例"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QJW11dLmnXMG"
      },
      "source": [
        "def TabNet_trick(op, pretrain_ratio, pretrain_epoch, finetune_epoch, finetune_lr):\n",
        "  tn_pre = TabNetPretrainer(\n",
        "        optimizer_fn = torch.optim.Adam,\n",
        "        optimizer_params = dict(lr=2e-2),\n",
        "        mask_type='entmax'\n",
        "        )\n",
        "\n",
        "  tn_pre.fit(\n",
        "      X_train = X_train,\n",
        "      eval_set = [X_eval],\n",
        "      pretraining_ratio=pretrain_ratio,\n",
        "      max_epochs=pretrain_epoch\n",
        "      )\n",
        "  \n",
        "  if op == 'Adam':\n",
        "    opt = torch.optim.Adam\n",
        "  elif op == 'SGD':\n",
        "    opt = torch.optim.SGD\n",
        "  elif op == 'Adadelta':\n",
        "    opt = torch.optim.Adadelta\n",
        "\n",
        "\n",
        "  tn1 = TabNetClassifier(\n",
        "          optimizer_fn=opt,\n",
        "          optimizer_params=dict(lr=finetune_lr),\n",
        "          scheduler_params={'step_size':10, 'gamma': 0.9},\n",
        "          scheduler_fn=torch.optim.lr_scheduler.StepLR,\n",
        "          mask_type='sparsemax'\n",
        "          )\n",
        "\n",
        "  tn1.fit(\n",
        "      X_train=X_train, y_train=Y_train,\n",
        "      eval_set=[(X_eval, Y_eval)],\n",
        "      eval_metric=['logloss'],\n",
        "      from_unsupervised=tn_pre,\n",
        "      max_epochs=finetune_epoch\n",
        "      )\n",
        "  \n",
        "  preds = tn1.predict(X_test)\n",
        "  acc = accuracy_score(Y_test, preds)\n",
        "  \n",
        "  print('Using {0}, pretrain max_epochs: {1}, pretrain ratio: {2}, finetune max epochs: {3}, the model on Test set obtains accuracy of {4}'\\\n",
        "        .format(op, pretrain_epoch, pretrain_ratio, finetune_epoch, acc))"
      ],
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pQDX6tM63Fzq",
        "outputId": "c194c86c-2da7-4691-ba5c-27ef8a23eef4"
      },
      "source": [
        "(0.91684 - 0.91602) / 0.91602"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.0008951769612017674"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Cl2bEyQp3Glh"
      },
      "source": [
        "当pretrain_epoch, finetune_epoch都为100，pretrain_ratio为0.9，优化器为Adam时，模型的准确率在0.91684，比最初结果（0.91602）提高0.09%."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1Jj8UpsJIj87"
      },
      "source": [
        "## b) DNN\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qmJYAcpgIiKl"
      },
      "source": [
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras import models\n",
        "import tensorflow.keras as K\n",
        "\n",
        "init = K.initializers.glorot_uniform(seed=1)\n",
        "inputs = layers.Input(shape = (145,))\n",
        "x = layers.Dense(200, kernel_initializer = init, activation='relu')(inputs)\n",
        "x = layers.Dense(100, kernel_initializer = init, activation='relu')(x)\n",
        "x = layers.Dense(50, kernel_initializer = init, activation='relu')(x)\n",
        "outputs = layers.Dense(2, kernel_initializer = init, activation='softmax')(x)\n",
        "model = models.Model(inputs, outputs)"
      ],
      "execution_count": 61,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JI4RgdoxZu3b"
      },
      "source": [
        "from tensorflow.keras.utils import to_categorical\n",
        "from tensorflow.keras import optimizers\n",
        "Y_test = to_categorical(Y_test, 2).astype(int)\n",
        "Y_train = to_categorical(Y_train, 2).astype(int)\n",
        "\n",
        "model.compile(loss='categorical_crossentropy', optimizer=optimizers.Adam(), metrics=['accuracy'])"
      ],
      "execution_count": 75,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VxAqsE2CYJ4P",
        "outputId": "806818c0-4828-4e75-b801-343f86079569"
      },
      "source": [
        "bs, epo = 256, 100\n",
        "model.fit(X_train, Y_train, batch_size = bs, epochs = epo, shuffle=True, verbose=1)"
      ],
      "execution_count": 76,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "137/137 [==============================] - 3s 2ms/step - loss: 245.2785 - accuracy: 0.6845\n",
            "Epoch 2/100\n",
            "137/137 [==============================] - 0s 2ms/step - loss: 46.1557 - accuracy: 0.6901\n",
            "Epoch 3/100\n",
            "137/137 [==============================] - 0s 2ms/step - loss: 36.2746 - accuracy: 0.7152\n",
            "Epoch 4/100\n",
            "137/137 [==============================] - 0s 2ms/step - loss: 22.6042 - accuracy: 0.7170\n",
            "Epoch 5/100\n",
            "137/137 [==============================] - 0s 3ms/step - loss: 25.3411 - accuracy: 0.7134\n",
            "Epoch 6/100\n",
            "137/137 [==============================] - 0s 2ms/step - loss: 18.9439 - accuracy: 0.7320\n",
            "Epoch 7/100\n",
            "137/137 [==============================] - 0s 2ms/step - loss: 14.4237 - accuracy: 0.7421\n",
            "Epoch 8/100\n",
            "137/137 [==============================] - 0s 2ms/step - loss: 7.4588 - accuracy: 0.7727\n",
            "Epoch 9/100\n",
            "137/137 [==============================] - 0s 2ms/step - loss: 8.5463 - accuracy: 0.7497\n",
            "Epoch 10/100\n",
            "137/137 [==============================] - 0s 3ms/step - loss: 7.7133 - accuracy: 0.7632\n",
            "Epoch 11/100\n",
            "137/137 [==============================] - 0s 2ms/step - loss: 4.6674 - accuracy: 0.8088\n",
            "Epoch 12/100\n",
            "137/137 [==============================] - 0s 2ms/step - loss: 9.1585 - accuracy: 0.7552\n",
            "Epoch 13/100\n",
            "137/137 [==============================] - 0s 2ms/step - loss: 5.5913 - accuracy: 0.7787\n",
            "Epoch 14/100\n",
            "137/137 [==============================] - 0s 2ms/step - loss: 5.4961 - accuracy: 0.7942\n",
            "Epoch 15/100\n",
            "137/137 [==============================] - 0s 2ms/step - loss: 3.3653 - accuracy: 0.8227\n",
            "Epoch 16/100\n",
            "137/137 [==============================] - 0s 2ms/step - loss: 2.5085 - accuracy: 0.8491\n",
            "Epoch 17/100\n",
            "137/137 [==============================] - 0s 2ms/step - loss: 3.5857 - accuracy: 0.7946\n",
            "Epoch 18/100\n",
            "137/137 [==============================] - 0s 2ms/step - loss: 1.9163 - accuracy: 0.8446\n",
            "Epoch 19/100\n",
            "137/137 [==============================] - 0s 2ms/step - loss: 1.6226 - accuracy: 0.8478\n",
            "Epoch 20/100\n",
            "137/137 [==============================] - 0s 2ms/step - loss: 1.4385 - accuracy: 0.8433\n",
            "Epoch 21/100\n",
            "137/137 [==============================] - 0s 2ms/step - loss: 2.9012 - accuracy: 0.7979\n",
            "Epoch 22/100\n",
            "137/137 [==============================] - 0s 2ms/step - loss: 1.0328 - accuracy: 0.8637\n",
            "Epoch 23/100\n",
            "137/137 [==============================] - 0s 2ms/step - loss: 0.7061 - accuracy: 0.8860\n",
            "Epoch 24/100\n",
            "137/137 [==============================] - 0s 2ms/step - loss: 1.0552 - accuracy: 0.8512\n",
            "Epoch 25/100\n",
            "137/137 [==============================] - 0s 2ms/step - loss: 2.2412 - accuracy: 0.7960\n",
            "Epoch 26/100\n",
            "137/137 [==============================] - 0s 2ms/step - loss: 0.9119 - accuracy: 0.8351\n",
            "Epoch 27/100\n",
            "137/137 [==============================] - 0s 2ms/step - loss: 0.7990 - accuracy: 0.8608\n",
            "Epoch 28/100\n",
            "137/137 [==============================] - 0s 3ms/step - loss: 0.4590 - accuracy: 0.8930\n",
            "Epoch 29/100\n",
            "137/137 [==============================] - 0s 2ms/step - loss: 0.6749 - accuracy: 0.8510\n",
            "Epoch 30/100\n",
            "137/137 [==============================] - 0s 2ms/step - loss: 0.8488 - accuracy: 0.8366\n",
            "Epoch 31/100\n",
            "137/137 [==============================] - 0s 3ms/step - loss: 0.7578 - accuracy: 0.8605\n",
            "Epoch 32/100\n",
            "137/137 [==============================] - 0s 2ms/step - loss: 1.0756 - accuracy: 0.8296\n",
            "Epoch 33/100\n",
            "137/137 [==============================] - 0s 2ms/step - loss: 0.5806 - accuracy: 0.8658\n",
            "Epoch 34/100\n",
            "137/137 [==============================] - 0s 2ms/step - loss: 0.5467 - accuracy: 0.8726\n",
            "Epoch 35/100\n",
            "137/137 [==============================] - 0s 2ms/step - loss: 0.6228 - accuracy: 0.8566\n",
            "Epoch 36/100\n",
            "137/137 [==============================] - 0s 2ms/step - loss: 0.5956 - accuracy: 0.8539\n",
            "Epoch 37/100\n",
            "137/137 [==============================] - 0s 2ms/step - loss: 0.4015 - accuracy: 0.8780\n",
            "Epoch 38/100\n",
            "137/137 [==============================] - 0s 2ms/step - loss: 0.3500 - accuracy: 0.8883\n",
            "Epoch 39/100\n",
            "137/137 [==============================] - 0s 2ms/step - loss: 0.3932 - accuracy: 0.8802\n",
            "Epoch 40/100\n",
            "137/137 [==============================] - 0s 2ms/step - loss: 0.4696 - accuracy: 0.8666\n",
            "Epoch 41/100\n",
            "137/137 [==============================] - 0s 2ms/step - loss: 0.3848 - accuracy: 0.8804\n",
            "Epoch 42/100\n",
            "137/137 [==============================] - 0s 2ms/step - loss: 0.2886 - accuracy: 0.8955\n",
            "Epoch 43/100\n",
            "137/137 [==============================] - 0s 2ms/step - loss: 0.4500 - accuracy: 0.8686\n",
            "Epoch 44/100\n",
            "137/137 [==============================] - 0s 2ms/step - loss: 1.5109 - accuracy: 0.7929\n",
            "Epoch 45/100\n",
            "137/137 [==============================] - 0s 2ms/step - loss: 0.4129 - accuracy: 0.8535\n",
            "Epoch 46/100\n",
            "137/137 [==============================] - 0s 2ms/step - loss: 0.2509 - accuracy: 0.9029\n",
            "Epoch 47/100\n",
            "137/137 [==============================] - 0s 2ms/step - loss: 0.3442 - accuracy: 0.8714\n",
            "Epoch 48/100\n",
            "137/137 [==============================] - 0s 2ms/step - loss: 0.2660 - accuracy: 0.8993\n",
            "Epoch 49/100\n",
            "137/137 [==============================] - 0s 2ms/step - loss: 0.2306 - accuracy: 0.9077\n",
            "Epoch 50/100\n",
            "137/137 [==============================] - 0s 2ms/step - loss: 0.2804 - accuracy: 0.8936\n",
            "Epoch 51/100\n",
            "137/137 [==============================] - 0s 2ms/step - loss: 0.2832 - accuracy: 0.8907\n",
            "Epoch 52/100\n",
            "137/137 [==============================] - 0s 2ms/step - loss: 0.2909 - accuracy: 0.8898\n",
            "Epoch 53/100\n",
            "137/137 [==============================] - 0s 2ms/step - loss: 0.2977 - accuracy: 0.8836\n",
            "Epoch 54/100\n",
            "137/137 [==============================] - 0s 2ms/step - loss: 0.2731 - accuracy: 0.8956\n",
            "Epoch 55/100\n",
            "137/137 [==============================] - 0s 2ms/step - loss: 0.3811 - accuracy: 0.8923\n",
            "Epoch 56/100\n",
            "137/137 [==============================] - 0s 2ms/step - loss: 4.7631 - accuracy: 0.7301\n",
            "Epoch 57/100\n",
            "137/137 [==============================] - 0s 2ms/step - loss: 0.4101 - accuracy: 0.8250\n",
            "Epoch 58/100\n",
            "137/137 [==============================] - 0s 2ms/step - loss: 0.3977 - accuracy: 0.8288\n",
            "Epoch 59/100\n",
            "137/137 [==============================] - 0s 2ms/step - loss: 0.3925 - accuracy: 0.8370\n",
            "Epoch 60/100\n",
            "137/137 [==============================] - 0s 2ms/step - loss: 0.3873 - accuracy: 0.8383\n",
            "Epoch 61/100\n",
            "137/137 [==============================] - 0s 2ms/step - loss: 0.5067 - accuracy: 0.8154\n",
            "Epoch 62/100\n",
            "137/137 [==============================] - 0s 2ms/step - loss: 0.5605 - accuracy: 0.7727\n",
            "Epoch 63/100\n",
            "137/137 [==============================] - 0s 2ms/step - loss: 0.4256 - accuracy: 0.8192\n",
            "Epoch 64/100\n",
            "137/137 [==============================] - 0s 2ms/step - loss: 0.4194 - accuracy: 0.8192\n",
            "Epoch 65/100\n",
            "137/137 [==============================] - 0s 2ms/step - loss: 0.5512 - accuracy: 0.8089\n",
            "Epoch 66/100\n",
            "137/137 [==============================] - 0s 2ms/step - loss: 0.4015 - accuracy: 0.8257\n",
            "Epoch 67/100\n",
            "137/137 [==============================] - 0s 2ms/step - loss: 0.3155 - accuracy: 0.8614\n",
            "Epoch 68/100\n",
            "137/137 [==============================] - 0s 2ms/step - loss: 0.3469 - accuracy: 0.8489\n",
            "Epoch 69/100\n",
            "137/137 [==============================] - 0s 2ms/step - loss: 0.3219 - accuracy: 0.8620\n",
            "Epoch 70/100\n",
            "137/137 [==============================] - 0s 2ms/step - loss: 0.3724 - accuracy: 0.8398\n",
            "Epoch 71/100\n",
            "137/137 [==============================] - 0s 2ms/step - loss: 0.3021 - accuracy: 0.8742\n",
            "Epoch 72/100\n",
            "137/137 [==============================] - 0s 2ms/step - loss: 0.3853 - accuracy: 0.8098\n",
            "Epoch 73/100\n",
            "137/137 [==============================] - 0s 2ms/step - loss: 0.2661 - accuracy: 0.8888\n",
            "Epoch 74/100\n",
            "137/137 [==============================] - 0s 2ms/step - loss: 0.2839 - accuracy: 0.8789\n",
            "Epoch 75/100\n",
            "137/137 [==============================] - 0s 2ms/step - loss: 0.2798 - accuracy: 0.8835\n",
            "Epoch 76/100\n",
            "137/137 [==============================] - 0s 2ms/step - loss: 0.2523 - accuracy: 0.8936\n",
            "Epoch 77/100\n",
            "137/137 [==============================] - 0s 2ms/step - loss: 0.2425 - accuracy: 0.8987\n",
            "Epoch 78/100\n",
            "137/137 [==============================] - 0s 2ms/step - loss: 0.2964 - accuracy: 0.8765\n",
            "Epoch 79/100\n",
            "137/137 [==============================] - 0s 3ms/step - loss: 0.2484 - accuracy: 0.8931\n",
            "Epoch 80/100\n",
            "137/137 [==============================] - 0s 2ms/step - loss: 0.2391 - accuracy: 0.9013\n",
            "Epoch 81/100\n",
            "137/137 [==============================] - 0s 3ms/step - loss: 0.2439 - accuracy: 0.8970\n",
            "Epoch 82/100\n",
            "137/137 [==============================] - 0s 3ms/step - loss: 0.2456 - accuracy: 0.8967\n",
            "Epoch 83/100\n",
            "137/137 [==============================] - 0s 2ms/step - loss: 0.2480 - accuracy: 0.8968\n",
            "Epoch 84/100\n",
            "137/137 [==============================] - 0s 2ms/step - loss: 0.2394 - accuracy: 0.9014\n",
            "Epoch 85/100\n",
            "137/137 [==============================] - 0s 2ms/step - loss: 0.2593 - accuracy: 0.8909\n",
            "Epoch 86/100\n",
            "137/137 [==============================] - 0s 2ms/step - loss: 0.2331 - accuracy: 0.9052\n",
            "Epoch 87/100\n",
            "137/137 [==============================] - 0s 2ms/step - loss: 0.2481 - accuracy: 0.8939\n",
            "Epoch 88/100\n",
            "137/137 [==============================] - 0s 2ms/step - loss: 0.2312 - accuracy: 0.9048\n",
            "Epoch 89/100\n",
            "137/137 [==============================] - 0s 2ms/step - loss: 0.2480 - accuracy: 0.8979\n",
            "Epoch 90/100\n",
            "137/137 [==============================] - 0s 2ms/step - loss: 0.2420 - accuracy: 0.8986\n",
            "Epoch 91/100\n",
            "137/137 [==============================] - 0s 2ms/step - loss: 0.2619 - accuracy: 0.8926\n",
            "Epoch 92/100\n",
            "137/137 [==============================] - 0s 2ms/step - loss: 0.2340 - accuracy: 0.9029\n",
            "Epoch 93/100\n",
            "137/137 [==============================] - 0s 2ms/step - loss: 0.2364 - accuracy: 0.9043\n",
            "Epoch 94/100\n",
            "137/137 [==============================] - 0s 2ms/step - loss: 0.2222 - accuracy: 0.9098\n",
            "Epoch 95/100\n",
            "137/137 [==============================] - 0s 2ms/step - loss: 0.2672 - accuracy: 0.8906\n",
            "Epoch 96/100\n",
            "137/137 [==============================] - 0s 2ms/step - loss: 0.2777 - accuracy: 0.8894\n",
            "Epoch 97/100\n",
            "137/137 [==============================] - 0s 2ms/step - loss: 0.2385 - accuracy: 0.8991\n",
            "Epoch 98/100\n",
            "137/137 [==============================] - 0s 2ms/step - loss: 0.2646 - accuracy: 0.8891\n",
            "Epoch 99/100\n",
            "137/137 [==============================] - 0s 2ms/step - loss: 0.2499 - accuracy: 0.8990\n",
            "Epoch 100/100\n",
            "137/137 [==============================] - 0s 2ms/step - loss: 0.2567 - accuracy: 0.8947\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f334e2d5210>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 76
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NjVeWDGbYJ1c",
        "outputId": "202b8cd1-fc59-452b-e9e9-d689219f8ed9"
      },
      "source": [
        "res = model.evaluate(X_test, Y_test, verbose=0)\n",
        "print('Evaluation on test data: loss = %0.6f, accuracy = %0.2f%% \\n' % (res[0], res[1]*100))"
      ],
      "execution_count": 77,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Evaluation on test data: loss = 0.216902, accuracy = 91.25% \n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t4QoV0HkhkYL"
      },
      "source": [
        "## c) 模型集成"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SD2oGeCai6i8"
      },
      "source": [
        "将DNN模型与前一章节的三个ML模型进行集成，比较准确率是否有提升"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fyuFWrD_RqCw"
      },
      "source": [
        "# ML model\n",
        "from sklearn.ensemble import VotingClassifier\n",
        "from xgboost.sklearn import XGBClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier as RF\n",
        "from sklearn.ensemble import GradientBoostingClassifier as GBDT\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "import xgboost as xgb\n",
        "from tensorflow import losses\n",
        "from tensorflow.keras import Sequential\n",
        "\n",
        "xgb_bst = XGBClassifier(max_depth = 3,\n",
        "                     learning_rate = 0.1,\n",
        "                     n_estimators = 202,\n",
        "                     silent=False,\n",
        "                     objective='binary:logistic',\n",
        "                     booster='gbtree',\n",
        "                     n_jobs=4,\n",
        "                     gamma = 7,\n",
        "                     min_child_weight=5,\n",
        "                     subsample=0.9,\n",
        "                     colsample_bytree=0.8,\n",
        "                     reg_lambda = 0.2,\n",
        "                     seed=7)\n",
        "\n",
        "rf_bst = RF(criterion = 'gini', \n",
        "               max_depth = 13, \n",
        "               min_samples_split = 70, \n",
        "               n_estimators = 70,\n",
        "           max_features = 'sqrt', random_state = 10)\n",
        "\n",
        "gbdt_bst = GBDT(n_estimators=51,\n",
        "            learning_rate = 0.1,\n",
        "            max_depth = 1,\n",
        "             min_samples_leaf = 3,\n",
        "             subsample=0.5,\n",
        "            n_iter_no_change = 500,\n",
        "            validation_fraction=0.7,\n",
        "            random_state = 0)\n",
        "\n",
        "# DNN model\n",
        "from tensorflow.keras.wrappers.scikit_learn import KerasClassifier\n",
        "def DNN_model():\n",
        "  model = Sequential([\n",
        "    layers.Dense(200, activation='relu', input_shape=(145,)),\n",
        "    layers.Dense(100, activation='relu'),\n",
        "    layers.Dense(50, activation='relu'),\n",
        "    layers.Dense(2, activation='softmax')\n",
        "  ])\n",
        "  model.compile(optimizer=optimizers.SGD(), loss=losses.SparseCategoricalCrossentropy(), metrics=['accuracy'])\n",
        "  return model\n",
        "\n",
        "dnn = KerasClassifier(build_fn = DNN_model, epochs = 100, verbose=0)\n",
        "dnn._estimator_type = \"classifier\""
      ],
      "execution_count": 110,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gteURNziKkGq"
      },
      "source": [
        "hd_vote = VotingClassifier(estimators=[   ('rf', rf_bst), \n",
        "                                          ('gbdt', gbdt_bst), \n",
        "                                          ('xgb', xgb_bst), \n",
        "                                          ('dnn', dnn)], \n",
        "                                          voting='hard')\n",
        "\n",
        "sf_vote = VotingClassifier(estimators=[   ('rf', rf_bst), \n",
        "                                          ('gbdt', gbdt_bst), \n",
        "                                          ('xgb', xgb_bst), \n",
        "                                          ('dnn', dnn)], \n",
        "                                          voting='soft', \n",
        "                                          weights = [2,1,3, 3])"
      ],
      "execution_count": 111,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZHr4jYMRm4Uu"
      },
      "source": [
        "Y_train = train_data['loan_status'].values.astype(int)\n",
        "Y_test = test_data['loan_status'].values.astype(int)\n"
      ],
      "execution_count": 105,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Oey4_FeQd-UP",
        "outputId": "5ac0fddc-c8ca-4feb-b712-a156fc9191b8"
      },
      "source": [
        "hd_vote.fit(X_train, Y_train)\n",
        "sf_vote.fit(X_train, Y_train)\n",
        "hd_preds = hd_vote.predict(X_test)\n",
        "sf_preds = sf_vote.predict(X_test)\n",
        "print('hard vote, acc: %0.2f%%' % (accuracy_score(Y_test, hd_preds) * 100))\n",
        "print('soft vote, acc: %0.2f%%' % (accuracy_score(Y_test, sf_preds) * 100))\n"
      ],
      "execution_count": 112,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/sequential.py:450: UserWarning: `model.predict_classes()` is deprecated and will be removed after 2021-01-01. Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n",
            "  warnings.warn('`model.predict_classes()` is deprecated and '\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/sequential.py:425: UserWarning: `model.predict_proba()` is deprecated and will be removed after 2021-01-01. Please use `model.predict()` instead.\n",
            "  warnings.warn('`model.predict_proba()` is deprecated and '\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "hard vote, acc: 91.50%\n",
            "soft vote, acc: 19.55%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UaSgRy3runjK"
      },
      "source": [
        "#### 本章小结\n",
        "- 使用了TabNet对结构化数据进行建模，并通过半监督预训练、Adam优化提高了模型的准确率\n",
        "- 搭建DNN对结构化数据进行建模，但结果未超过baseline\n",
        "- 将DNN和上一章节的三个机器学习模型进行投票选举融合，得到模型的准确率为91.50%，相比单一模型均有提升，但soft vote结果较差。"
      ]
    }
  ]
}